<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>2026年AI大模型爆发：从千问3.5到GPT-5.2，谁将引领AGI时代</title>
    <url>/2026/02/18/2026%E5%B9%B4AI%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%88%86%E5%8F%91%EF%BC%9A%E4%BB%8E%E5%8D%83%E9%97%AE3-5%E5%88%B0GPT-5-2%EF%BC%8C%E8%B0%81%E5%B0%86%E5%BC%95%E9%A2%86AGI%E6%97%B6%E4%BB%A3/</url>
    <content><![CDATA[<h2 id="引言：2026年——AI的”模型大爆发”之年"><a href="#引言：2026年——AI的”模型大爆发”之年" class="headerlink" title="引言：2026年——AI的”模型大爆发”之年"></a>引言：2026年——AI的”模型大爆发”之年</h2><p>如果说2023年是ChatGPT引爆全球的”AI元年”，2024年是多模态崛起的”图像之年”，2025年是推理模型突破的”思考元年”，那么<strong>2026年注定被历史铭记为”模型大爆发”之年</strong>。</p>
<p>2026年2月，全球AI行业正在经历前所未有的事件——<strong>7个主要AI模型计划在同一个月内发布</strong>，整个行业已进入”Model Rush”（模型大爆发）状态：</p>
<table>
<thead>
<tr>
<th>模型</th>
<th>开发方</th>
<th>定位</th>
</tr>
</thead>
<tbody><tr>
<td>Gemini 3 Pro GA</td>
<td>Google DeepMind</td>
<td>旗舰多模态推理</td>
</tr>
<tr>
<td>Claude Opus 4.6</td>
<td>Anthropic</td>
<td>百万token上下文</td>
</tr>
<tr>
<td>GPT-5.3</td>
<td>OpenAI</td>
<td>推理+编程融合</td>
</tr>
<tr>
<td><strong>Qwen 3.5</strong></td>
<td>阿里云</td>
<td>开源SOTA</td>
</tr>
<tr>
<td>GLM 5</td>
<td>智谱AI</td>
<td>Agent能力突破</td>
</tr>
<tr>
<td>DeepSeek V4</td>
<td>DeepSeek</td>
<td>推理特化</td>
</tr>
<tr>
<td>Grok 4.20</td>
<td>xAI</td>
<td>实时信息处理</td>
</tr>
</tbody></table>
<p>这场史无前例的竞争背后，是AI行业从”生成”到”推理”、从”对话”到”执行”、从”单点突破”到”生态竞争”的范式转移。</p>
<hr>
<h2 id="一、千问3-5：中国开源的”SOTA时刻”"><a href="#一、千问3-5：中国开源的”SOTA时刻”" class="headerlink" title="一、千问3.5：中国开源的”SOTA时刻”"></a>一、千问3.5：中国开源的”SOTA时刻”</h2><h3 id="1-1-参数效率的革命性突破"><a href="#1-1-参数效率的革命性突破" class="headerlink" title="1.1 参数效率的革命性突破"></a>1.1 参数效率的革命性突破</h3><p>2026年2月16日除夕当天，阿里巴巴开源了全新一代大模型<strong>千问 Qwen3.5-Plus</strong>，这一发布被视为中国AI”两弹一星”时刻的重要组成部分。</p>
<p>千问3.5最令人震惊的不是其绝对性能，而是<strong>参数效率的革命性突破</strong>：</p>
<table>
<thead>
<tr>
<th>指标</th>
<th>Qwen3.5-Plus</th>
<th>Qwen3-Max</th>
</tr>
</thead>
<tbody><tr>
<td>总参数量</td>
<td>3970亿</td>
<td>万亿级</td>
</tr>
<tr>
<td>激活参数</td>
<td><strong>170亿</strong></td>
<td>500亿+</td>
</tr>
<tr>
<td>部署显存</td>
<td>降低60%</td>
<td>基准</td>
</tr>
<tr>
<td>推理吞吐</td>
<td><strong>提升19倍</strong></td>
<td>基准</td>
</tr>
</tbody></table>
<p>这意味着，千问3.5以<strong>不到40%的参数量</strong>，获得了超越万亿参数模型的顶尖性能。</p>
<h3 id="1-2-评测表现：全面超越"><a href="#1-2-评测表现：全面超越" class="headerlink" title="1.2 评测表现：全面超越"></a>1.2 评测表现：全面超越</h3><p>千问3.5在多项权威评测中刷新纪录：</p>
<ul>
<li><strong>MMLU-Pro</strong>（知识推理）：87.8分，超越GPT-5.2</li>
<li><strong>GPQA</strong>（博士级难题）：88.4分，超越Claude 4.5</li>
<li><strong>IFBench</strong>（指令遵循）：76.5分，<strong>刷新所有模型纪录</strong></li>
<li><strong>BFCL-V4</strong>（通用Agent）：超越Gemini 3 Pro</li>
<li><strong>Browsecomp</strong>（搜索Agent）：超越GPT-5.2</li>
</ul>
<h3 id="1-3-成本优势：1-18的价格革命"><a href="#1-3-成本优势：1-18的价格革命" class="headerlink" title="1.3 成本优势：1&#x2F;18的价格革命"></a>1.3 成本优势：1&#x2F;18的价格革命</h3><p>在性能媲美顶级闭源模型的同时，千问3.5的成本优势令人咋舌：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">每百万Token输入价格对比：</span><br><span class="line">- GPT-5.2:      约12元</span><br><span class="line">- Gemini 3 Pro: 约14.4元</span><br><span class="line">- Qwen 3.5:     仅0.8元（仅为Gemini的1/18）</span><br></pre></td></tr></table></figure>

<h3 id="1-4-原生多模态的代际跃迁"><a href="#1-4-原生多模态的代际跃迁" class="headerlink" title="1.4 原生多模态的代际跃迁"></a>1.4 原生多模态的代际跃迁</h3><p>千问3.5最大的技术突破在于实现了<strong>从纯文本模型到原生多模态模型的代际跃迁</strong>：</p>
<ul>
<li>千问3：在纯文本Tokens上预训练</li>
<li>千问3.5：在<strong>视觉和文本混合token</strong>上预训练</li>
</ul>
<p>这种原生多模态架构使得千问3.5可以：</p>
<ul>
<li>自主操作手机与电脑</li>
<li>高效完成复杂Agent任务</li>
<li>实现像素级视觉定位</li>
</ul>
<hr>
<h2 id="二、OpenAI-o3：推理革命的里程碑"><a href="#二、OpenAI-o3：推理革命的里程碑" class="headerlink" title="二、OpenAI o3：推理革命的里程碑"></a>二、OpenAI o3：推理革命的里程碑</h2><h3 id="2-1-“慢思考”AI的诞生"><a href="#2-1-“慢思考”AI的诞生" class="headerlink" title="2.1 “慢思考”AI的诞生"></a>2.1 “慢思考”AI的诞生</h3><p>2025年底至2026年初，OpenAI的o系列模型（o1、o3）标志着AI从”即时响应”向”深度思考”的范式转变。</p>
<p><strong>“慢AI”（Slow AI）</strong> 的核心理念是：</p>
<blockquote>
<p>与其快速给出可能错误的答案，不如花时间深入思考，给出更可靠的结论。</p>
</blockquote>
<h3 id="2-2-ARC-AGI：突破历史性壁垒"><a href="#2-2-ARC-AGI：突破历史性壁垒" class="headerlink" title="2.2 ARC-AGI：突破历史性壁垒"></a>2.2 ARC-AGI：突破历史性壁垒</h3><p>OpenAI o3在<strong>ARC-AGI基准测试</strong>中取得了突破性成绩。这个被AI研究者视为”AGI最后一道屏障”的测试，多年来几乎所有模型都难以突破。o3的成功意味着：</p>
<ol>
<li><strong>抽象推理能力</strong>达到新高度</li>
<li><strong>模式识别与泛化</strong>能力超越前代</li>
<li><strong>复杂问题分解</strong>能力接近人类水平</li>
</ol>
<h3 id="2-3-GPT-5-2与Deep-Research"><a href="#2-3-GPT-5-2与Deep-Research" class="headerlink" title="2.3 GPT-5.2与Deep Research"></a>2.3 GPT-5.2与Deep Research</h3><p>2026年2月，OpenAI将Deep Research升级至<strong>GPT-5.2</strong>，这一功能被视为ChatGPT中的<strong>首个真正意义上的AI Agent</strong>：</p>
<ul>
<li>可连接外部应用</li>
<li>可搜索特定网站</li>
<li>支持实时进度追踪</li>
<li>输出全屏研究报告</li>
</ul>
<hr>
<h2 id="三、Claude-Opus-4-6：百万上下文的边界突破"><a href="#三、Claude-Opus-4-6：百万上下文的边界突破" class="headerlink" title="三、Claude Opus 4.6：百万上下文的边界突破"></a>三、Claude Opus 4.6：百万上下文的边界突破</h2><h3 id="3-1-上下文窗口的极限挑战"><a href="#3-1-上下文窗口的极限挑战" class="headerlink" title="3.1 上下文窗口的极限挑战"></a>3.1 上下文窗口的极限挑战</h3><p>Anthropic发布的<strong>Claude Opus 4.6</strong>带来了一个里程碑式的突破：</p>
<blockquote>
<p><strong>首创百万token上下文窗口</strong></p>
</blockquote>
<p>这意味着：</p>
<ul>
<li>可处理约75万字的中文内容</li>
<li>可一次性阅读多本完整书籍</li>
<li>可分析超长代码库</li>
<li>可理解完整业务流程</li>
</ul>
<h3 id="3-2-Terminal-Bench-2-0领先"><a href="#3-2-Terminal-Bench-2-0领先" class="headerlink" title="3.2 Terminal-Bench 2.0领先"></a>3.2 Terminal-Bench 2.0领先</h3><p>在编程能力评测中，Opus 4.6在<strong>Terminal-Bench 2.0</strong>等评测中领先，特别是在：</p>
<ul>
<li>GDPval-AA评测中超GPT-5.2达<strong>144 Elo分</strong></li>
<li>编码、推理与代理任务能力全面提升</li>
<li>定价维持$5&#x2F;$25每百万token不变</li>
</ul>
<hr>
<h2 id="四、DeepSeek与GLM：中国AI的集体突围"><a href="#四、DeepSeek与GLM：中国AI的集体突围" class="headerlink" title="四、DeepSeek与GLM：中国AI的集体突围"></a>四、DeepSeek与GLM：中国AI的集体突围</h2><h3 id="4-1-DeepSeek：持续领跑开源推理"><a href="#4-1-DeepSeek：持续领跑开源推理" class="headerlink" title="4.1 DeepSeek：持续领跑开源推理"></a>4.1 DeepSeek：持续领跑开源推理</h3><p>DeepSeek自2025年春节发布R1以来，持续引领开源推理模型的发展。DeepSeek V4预期将带来：</p>
<ul>
<li>更强的<strong>数学推理</strong>能力（R1已达79.8% AIME）</li>
<li>更优的<strong>可见思考链</strong>（Visible Thinking）</li>
<li>更低的<strong>部署成本</strong></li>
</ul>
<h3 id="4-2-智谱GLM-5：硅谷神秘模型的真相"><a href="#4-2-智谱GLM-5：硅谷神秘模型的真相" class="headerlink" title="4.2 智谱GLM-5：硅谷神秘模型的真相"></a>4.2 智谱GLM-5：硅谷神秘模型的真相</h3><p>2026年春节期间，一个代号为**”Pony Alpha”**的神秘模型在OpenRouter上引发轰动：</p>
<ul>
<li>完全无人干预下自主修复代码</li>
<li>耗时数天构建C语言编译器</li>
<li>从零开发手机应用并上架应用商店</li>
</ul>
<p>2月11日，谜底揭晓——<strong>Pony Alpha来自中国智谱AI的GLM-5</strong>。</p>
<p>这一事件的市场反响：</p>
<ul>
<li>GLM Coding Plan上线即售罄</li>
<li>智谱股价单日大涨40%，周涨幅120%</li>
<li>摩根大通首次覆盖智谱，给予”买入”评级</li>
</ul>
<hr>
<h2 id="五、技术趋势：从模型到Agent的范式转移"><a href="#五、技术趋势：从模型到Agent的范式转移" class="headerlink" title="五、技术趋势：从模型到Agent的范式转移"></a>五、技术趋势：从模型到Agent的范式转移</h2><h3 id="5-1-强化学习的崛起"><a href="#5-1-强化学习的崛起" class="headerlink" title="5.1 强化学习的崛起"></a>5.1 强化学习的崛起</h3><p>2026年，<strong>强化学习（RL）</strong> 成为提升模型高级能力的关键：</p>
<table>
<thead>
<tr>
<th>技术方向</th>
<th>代表模型</th>
<th>核心突破</th>
</tr>
</thead>
<tbody><tr>
<td>推理增强</td>
<td>o3、DeepSeek R1</td>
<td>自我生成数据+多轮迭代</td>
</tr>
<tr>
<td>代码优化</td>
<td>GPT-5.3-Codex</td>
<td>编程+推理融合</td>
</tr>
<tr>
<td>Agent执行</td>
<td>Claude Code</td>
<td>终端操作自动化</td>
</tr>
</tbody></table>
<h3 id="5-2-多模态：从”加模态”到”建世界”"><a href="#5-2-多模态：从”加模态”到”建世界”" class="headerlink" title="5.2 多模态：从”加模态”到”建世界”"></a>5.2 多模态：从”加模态”到”建世界”</h3><p>2026年的多模态不再是简单地”加上图像&#x2F;视频能力”，而是：</p>
<blockquote>
<p><strong>构建对物理世界的完整理解</strong></p>
</blockquote>
<ul>
<li><strong>视频理解</strong>：处理长视频、理解时序关系</li>
<li><strong>世界模型</strong>：模拟物理规律、时空关系</li>
<li><strong>具身智能</strong>：与物理世界交互的能力</li>
</ul>
<h3 id="5-3-AI-Agent：从概念到生产力"><a href="#5-3-AI-Agent：从概念到生产力" class="headerlink" title="5.3 AI Agent：从概念到生产力"></a>5.3 AI Agent：从概念到生产力</h3><p>2025年被称为”AI Agent元年”，2026年则是Agent<strong>规模化落地</strong>之年：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Agent能力演进：</span><br><span class="line">感知 → 决策 → 行动 → 记忆 → 学习</span><br></pre></td></tr></table></figure>

<p><strong>核心突破</strong>：</p>
<ul>
<li><strong>MCP协议</strong>：Model Context Protocol，解决Agent互联互通</li>
<li><strong>A2A协议</strong>：Agent-to-Agent，多Agent协同</li>
<li><strong>可信智能体</strong>：解决幻觉、黑盒、行业知识三大痛点</li>
</ul>
<hr>
<h2 id="六、开源vs闭源：格局的重塑"><a href="#六、开源vs闭源：格局的重塑" class="headerlink" title="六、开源vs闭源：格局的重塑"></a>六、开源vs闭源：格局的重塑</h2><h3 id="6-1-开源模型的崛起"><a href="#6-1-开源模型的崛起" class="headerlink" title="6.1 开源模型的崛起"></a>6.1 开源模型的崛起</h3><p>根据Hugging Face数据，2025年底开源模型与闭源模型的性能差距已从<strong>17.5个百分点缩小到仅0.3%</strong>。</p>
<p><strong>2026年开源LLM排行榜</strong>：</p>
<table>
<thead>
<tr>
<th>排名</th>
<th>领域</th>
<th>模型</th>
<th>核心优势</th>
</tr>
</thead>
<tbody><tr>
<td>🏆</td>
<td>最佳推理</td>
<td>DeepSeek R1</td>
<td>79.8% AIME，可见思考</td>
</tr>
<tr>
<td>👁️</td>
<td>最佳多模态</td>
<td>Llama 4 Maverick</td>
<td>视觉+文本，10M上下文</td>
</tr>
<tr>
<td>💻</td>
<td>最佳编程</td>
<td>Qwen 2.5 Coder 32B</td>
<td>92% HumanEval</td>
</tr>
</tbody></table>
<h3 id="6-2-中国开源的全球影响力"><a href="#6-2-中国开源的全球影响力" class="headerlink" title="6.2 中国开源的全球影响力"></a>6.2 中国开源的全球影响力</h3><p><strong>DeepSeek + Qwen已占据全球AI市场约15%</strong>，从2025年初的1%实现爆发式增长。</p>
<p>开源生态的变化：</p>
<ul>
<li>Qwen超越Llama成为下载量最多的开源模型家族</li>
<li>中国开源模型在GitHub Star、社区贡献等指标全面领先</li>
<li>MIT&#x2F;Apache 2.0许可证成为主流，商业化无障碍</li>
</ul>
<hr>
<h2 id="七、AGI之路：我们还有多远？"><a href="#七、AGI之路：我们还有多远？" class="headerlink" title="七、AGI之路：我们还有多远？"></a>七、AGI之路：我们还有多远？</h2><h3 id="7-1-2026年的AGI判断"><a href="#7-1-2026年的AGI判断" class="headerlink" title="7.1 2026年的AGI判断"></a>7.1 2026年的AGI判断</h3><p>多位顶级研究者的共识：</p>
<blockquote>
<p><strong>AGI不再是”是否”的问题，而是”何时”的问题。</strong></p>
</blockquote>
<p>2026年的技术趋势指向三个核心方向：</p>
<ol>
<li><strong>多模态</strong>（尤其是视频）</li>
<li><strong>强化学习</strong>（自主进化）</li>
<li><strong>自学习系统</strong>（System 3）</li>
</ol>
<h3 id="7-2-剩余挑战"><a href="#7-2-剩余挑战" class="headerlink" title="7.2 剩余挑战"></a>7.2 剩余挑战</h3><p>尽管进展巨大，通往AGI仍有关键挑战：</p>
<table>
<thead>
<tr>
<th>挑战</th>
<th>现状</th>
<th>预期突破</th>
</tr>
</thead>
<tbody><tr>
<td>灾难性遗忘</td>
<td>仍存在</td>
<td>Titans、持续学习</td>
</tr>
<tr>
<td>世界模型</td>
<td>初步探索</td>
<td>2026年加速</td>
</tr>
<tr>
<td>自主学习</td>
<td>起步阶段</td>
<td>2027年可能突破</td>
</tr>
<tr>
<td>能耗与算力</td>
<td>持续优化</td>
<td>需硬件配合</td>
</tr>
</tbody></table>
<hr>
<h2 id="结语：2026——AI历史的关键转折点"><a href="#结语：2026——AI历史的关键转折点" class="headerlink" title="结语：2026——AI历史的关键转折点"></a>结语：2026——AI历史的关键转折点</h2><p>2026年的春节，注定被写入AI发展史。</p>
<p>如果说2025年春节是DeepSeek的”孤勇者时刻”，那么2026年的春节，中国AI呈现的是<strong>视觉、工程、基座三线齐发的集团突破</strong>。</p>
<p>从千问3.5的开源SOTA，到GLM-5的Agent能力突破，再到DeepSeek的持续领跑，中国AI界已实质上完成了数字时代的**”两弹一星”战略部署**。</p>
<p>这场竞赛没有终点，但2026年的起点，值得我们铭记。</p>
<hr>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol>
<li>澎湃新闻：《阿里除夕开源千问3.5：性能媲美Gemini 3 Pro》</li>
<li>MIT Technology Review：《What’s next for Chinese open-source AI》</li>
<li>腾讯云开发者社区：《2026大模型三巨头横评》</li>
<li>北京智源人工智能研究院：《2026十大AI技术趋势》</li>
<li>OpenAI官方博客：《Introducing OpenAI o3 and o4-mini》</li>
<li>36氪：《请回答2026：38位中国AI关键人物的趋势判断》</li>
</ol>
]]></content>
      <categories>
        <category>AI前沿</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>大模型</tag>
        <tag>GPT-5</tag>
        <tag>DeepSeek</tag>
        <tag>千问</tag>
        <tag>AGI</tag>
      </tags>
  </entry>
  <entry>
    <title>2026年最值得收藏的开发者工具与资源清单</title>
    <url>/2026/02/20/2026%E5%B9%B4%E6%9C%80%E5%80%BC%E5%BE%97%E6%94%B6%E8%97%8F%E7%9A%84%E5%BC%80%E5%8F%91%E8%80%85%E5%B7%A5%E5%85%B7%E4%B8%8E%E8%B5%84%E6%BA%90%E6%B8%85%E5%8D%95/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>工欲善其事，必先利其器。在技术日新月异的 2026 年，选择正确的工具能够极大地提升开发效率。本文整理了覆盖多个领域的优质工具与免费资源，值得每一位开发者收藏。</p>
<h2 id="一、代码编辑器-IDE"><a href="#一、代码编辑器-IDE" class="headerlink" title="一、代码编辑器 &amp; IDE"></a>一、代码编辑器 &amp; IDE</h2><h3 id="VS-Code（免费）"><a href="#VS-Code（免费）" class="headerlink" title="VS Code（免费）"></a>VS Code（免费）</h3><p>依然是 2026 年最受欢迎的代码编辑器。推荐必装插件：</p>
<ul>
<li><strong>GitHub Copilot</strong> — AI 代码补全</li>
<li><strong>Error Lens</strong> — 行内显示错误信息</li>
<li><strong>Thunder Client</strong> — 轻量 API 测试工具</li>
<li><strong>GitLens</strong> — Git 历史可视化</li>
</ul>
<h3 id="Cursor（免费-付费）"><a href="#Cursor（免费-付费）" class="headerlink" title="Cursor（免费&#x2F;付费）"></a>Cursor（免费&#x2F;付费）</h3><p>基于 VS Code 的 AI-first 编辑器，内置强大的 AI 编程助手，支持多模型切换。适合重度使用 AI 辅助编程的开发者。</p>
<h3 id="JetBrains-全家桶（付费-学生免费）"><a href="#JetBrains-全家桶（付费-学生免费）" class="headerlink" title="JetBrains 全家桶（付费&#x2F;学生免费）"></a>JetBrains 全家桶（付费&#x2F;学生免费）</h3><p>WebStorm、IntelliJ IDEA、PyCharm 等，功能全面、重构能力强。学生可申请免费教育许可证。</p>
<h2 id="二、AI-编程助手"><a href="#二、AI-编程助手" class="headerlink" title="二、AI 编程助手"></a>二、AI 编程助手</h2><table>
<thead>
<tr>
<th>工具</th>
<th>特点</th>
<th>价格</th>
</tr>
</thead>
<tbody><tr>
<td>GitHub Copilot</td>
<td>深度集成 VS Code，代码补全精准</td>
<td>$10&#x2F;月</td>
</tr>
<tr>
<td>Cursor</td>
<td>AI-first 编辑器，支持多模型</td>
<td>免费版可用</td>
</tr>
<tr>
<td>Codeium</td>
<td>免费 AI 代码补全</td>
<td>免费</td>
</tr>
<tr>
<td>Claude Code</td>
<td>终端 AI 编程助手，自主完成复杂任务</td>
<td>按量付费</td>
</tr>
</tbody></table>
<h2 id="三、设计-UI-资源"><a href="#三、设计-UI-资源" class="headerlink" title="三、设计 &amp; UI 资源"></a>三、设计 &amp; UI 资源</h2><h3 id="Figma（免费-付费）"><a href="#Figma（免费-付费）" class="headerlink" title="Figma（免费&#x2F;付费）"></a>Figma（免费&#x2F;付费）</h3><p>协作设计工具的行业标准。个人项目免费，团队协作需订阅。</p>
<h3 id="免费图标库"><a href="#免费图标库" class="headerlink" title="免费图标库"></a>免费图标库</h3><ul>
<li><strong>Lucide Icons</strong> — 简洁现代的开源图标集</li>
<li><strong>Heroicons</strong> — Tailwind CSS 官方图标</li>
<li><strong>Phosphor Icons</strong> — 灵活可定制的图标家族</li>
<li><strong>阿里巴巴矢量图标库（iconfont）</strong> — 国内最大的图标资源平台</li>
</ul>
<h3 id="免费图片资源"><a href="#免费图片资源" class="headerlink" title="免费图片资源"></a>免费图片资源</h3><ul>
<li><strong>Unsplash</strong> — 高质量免费摄影图片</li>
<li><strong>Pexels</strong> — 免费高清图库</li>
<li><strong>picsum.photos</strong> — 随机占位图片 API</li>
<li><strong>Undraw</strong> — 免费扁平化插画</li>
</ul>
<h2 id="四、部署-托管"><a href="#四、部署-托管" class="headerlink" title="四、部署 &amp; 托管"></a>四、部署 &amp; 托管</h2><h3 id="Vercel（免费）"><a href="#Vercel（免费）" class="headerlink" title="Vercel（免费）"></a>Vercel（免费）</h3><p>前端项目首选部署平台。支持 Next.js、Nuxt、Hexo 等框架的一键部署，自带全球 CDN 和 HTTPS。</p>
<h3 id="Cloudflare-Pages（免费）"><a href="#Cloudflare-Pages（免费）" class="headerlink" title="Cloudflare Pages（免费）"></a>Cloudflare Pages（免费）</h3><p>零成本托管静态网站，无限带宽，全球 CDN 加速。</p>
<h3 id="GitHub-Pages（免费）"><a href="#GitHub-Pages（免费）" class="headerlink" title="GitHub Pages（免费）"></a>GitHub Pages（免费）</h3><p>配合 Hexo、Hugo、Jekyll 等静态生成器，完全免费的博客托管方案。</p>
<h3 id="Railway-Render（免费额度）"><a href="#Railway-Render（免费额度）" class="headerlink" title="Railway &#x2F; Render（免费额度）"></a>Railway &#x2F; Render（免费额度）</h3><p>后端服务部署平台，支持 Docker、Node.js、Python 等，提供免费额度。</p>
<h2 id="五、数据库-后端服务"><a href="#五、数据库-后端服务" class="headerlink" title="五、数据库 &amp; 后端服务"></a>五、数据库 &amp; 后端服务</h2><ul>
<li><strong>Supabase</strong> — 开源 Firebase 替代品，免费额度慷慨</li>
<li><strong>PlanetScale</strong> — 无服务器 MySQL 平台</li>
<li><strong>Upstash</strong> — 无服务器 Redis 和 Kafka</li>
<li><strong>Neon</strong> — 无服务器 PostgreSQL</li>
</ul>
<h2 id="六、效率工具"><a href="#六、效率工具" class="headerlink" title="六、效率工具"></a>六、效率工具</h2><h3 id="终端工具"><a href="#终端工具" class="headerlink" title="终端工具"></a>终端工具</h3><ul>
<li><strong>Warp</strong> — AI 增强的现代终端（macOS&#x2F;Linux）</li>
<li><strong>Windows Terminal</strong> — Windows 下最佳终端体验</li>
<li><strong>Oh My Zsh</strong> — Zsh 配置框架，提升命令行体验</li>
<li><strong>Starship</strong> — 跨平台极速命令提示符</li>
</ul>
<h3 id="知识管理"><a href="#知识管理" class="headerlink" title="知识管理"></a>知识管理</h3><ul>
<li><strong>Obsidian</strong> — 本地优先的 Markdown 知识库</li>
<li><strong>Notion</strong> — 全能型协作文档工具</li>
<li><strong>Logseq</strong> — 开源双向链接笔记工具</li>
</ul>
<h2 id="七、学习资源"><a href="#七、学习资源" class="headerlink" title="七、学习资源"></a>七、学习资源</h2><h3 id="在线学习平台"><a href="#在线学习平台" class="headerlink" title="在线学习平台"></a>在线学习平台</h3><ul>
<li><strong>freeCodeCamp</strong> — 免费交互式编程课程</li>
<li><strong>The Odin Project</strong> — 免费全栈 Web 开发课程</li>
<li><strong>MDN Web Docs</strong> — 权威 Web 技术文档</li>
<li><strong>CS自学指南</strong> — 中文 CS 自学路线图</li>
</ul>
<h3 id="技术社区"><a href="#技术社区" class="headerlink" title="技术社区"></a>技术社区</h3><ul>
<li><strong>GitHub</strong> — 开源世界的中心</li>
<li><strong>Stack Overflow</strong> — 编程问答社区</li>
<li><strong>掘金</strong> — 国内优质技术社区</li>
<li><strong>V2EX</strong> — 创意工作者社区</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以上工具和资源绝大多数提供免费方案，足以覆盖个人开发者的日常需求。建议根据自己的技术栈和工作流选择合适的组合，切忌贪多嚼不烂。</p>
<blockquote>
<p>好的工具是生产力的放大器，但真正的核心竞争力永远是你解决问题的能力。</p>
</blockquote>
]]></content>
      <categories>
        <category>资源服务</category>
      </categories>
      <tags>
        <tag>开发工具</tag>
        <tag>资源推荐</tag>
        <tag>效率</tag>
        <tag>开源</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博客搭建指南：从零开始打造个人技术博客</title>
    <url>/2026/02/19/Hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%8C%87%E5%8D%97%EF%BC%9A%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%89%93%E9%80%A0%E4%B8%AA%E4%BA%BA%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>搭建一个属于自己的博客，是每个技术人的必经之路。相比 WordPress 等动态博客系统，Hexo 以其极快的生成速度、丰富的主题生态和零服务器成本（配合 GitHub Pages），成为了静态博客的首选方案。</p>
<p>本文将从零开始，手把手带你完成一个精美 Hexo 博客的搭建。</p>
<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>在开始之前，你需要确保系统中已安装以下工具：</p>
<ul>
<li><strong>Node.js</strong>（推荐 v18+）</li>
<li><strong>Git</strong></li>
<li><strong>npm</strong> 或 <strong>yarn</strong></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 检查 Node.js 版本</span></span><br><span class="line">node -v</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查 Git 版本</span></span><br><span class="line">git --version</span><br></pre></td></tr></table></figure>

<h2 id="安装-Hexo"><a href="#安装-Hexo" class="headerlink" title="安装 Hexo"></a>安装 Hexo</h2><p>通过 npm 全局安装 Hexo CLI：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure>

<p>创建一个新的 Hexo 项目：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo init my-blog</span><br><span class="line"><span class="built_in">cd</span> my-blog</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure>

<p>启动本地预览服务器：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo server</span><br></pre></td></tr></table></figure>

<p>访问 <code>http://localhost:4000</code> 即可看到默认的 Hexo 博客页面。</p>
<h2 id="选择主题"><a href="#选择主题" class="headerlink" title="选择主题"></a>选择主题</h2><p>Hexo 的主题生态非常丰富，以下是几个高质量的推荐：</p>
<table>
<thead>
<tr>
<th>主题名称</th>
<th>特点</th>
<th>适合场景</th>
</tr>
</thead>
<tbody><tr>
<td>AnZhiYu</td>
<td>功能丰富、视觉精美</td>
<td>个人博客</td>
</tr>
<tr>
<td>Butterfly</td>
<td>高度可定制</td>
<td>技术博客</td>
</tr>
<tr>
<td>NexT</td>
<td>简洁优雅</td>
<td>学术&#x2F;技术</td>
</tr>
<tr>
<td>Fluid</td>
<td>现代化设计</td>
<td>通用</td>
</tr>
</tbody></table>
<h3 id="安装-AnZhiYu-主题"><a href="#安装-AnZhiYu-主题" class="headerlink" title="安装 AnZhiYu 主题"></a>安装 AnZhiYu 主题</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> -b main https://github.com/anzhiyu-c/hexo-theme-anzhiyu.git themes/anzhiyu</span><br></pre></td></tr></table></figure>

<p>修改 <code>_config.yml</code> 中的主题配置：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">theme:</span> <span class="string">anzhiyu</span></span><br></pre></td></tr></table></figure>

<h2 id="基础配置"><a href="#基础配置" class="headerlink" title="基础配置"></a>基础配置</h2><p>编辑项目根目录下的 <code>_config.yml</code>：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">title:</span> <span class="string">你的博客名称</span></span><br><span class="line"><span class="attr">subtitle:</span> <span class="string">一句话介绍</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">SEO</span> <span class="string">描述</span></span><br><span class="line"><span class="attr">author:</span> <span class="string">你的名字</span></span><br><span class="line"><span class="attr">language:</span> <span class="string">zh-CN</span></span><br><span class="line"><span class="attr">timezone:</span> <span class="string">Asia/Shanghai</span></span><br><span class="line"><span class="attr">url:</span> <span class="string">https://你的用户名.github.io</span></span><br></pre></td></tr></table></figure>

<h2 id="写第一篇文章"><a href="#写第一篇文章" class="headerlink" title="写第一篇文章"></a>写第一篇文章</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo new <span class="string">&quot;我的第一篇博客&quot;</span></span><br></pre></td></tr></table></figure>

<p>这会在 <code>source/_posts/</code> 目录下生成一个 Markdown 文件。使用你喜欢的编辑器打开它，开始写作吧！</p>
<h3 id="Markdown-小技巧"><a href="#Markdown-小技巧" class="headerlink" title="Markdown 小技巧"></a>Markdown 小技巧</h3><ul>
<li>使用 <code>##</code> 创建标题层级</li>
<li>使用 <code>`</code> 包裹行内代码</li>
<li>使用 <code>![](url)</code> 插入图片</li>
<li>使用 <code>&gt; </code> 创建引用块</li>
</ul>
<h2 id="部署到-GitHub-Pages"><a href="#部署到-GitHub-Pages" class="headerlink" title="部署到 GitHub Pages"></a>部署到 GitHub Pages</h2><ol>
<li>在 GitHub 上创建名为 <code>&lt;用户名&gt;.github.io</code> 的仓库</li>
<li>安装部署插件：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>在 <code>_config.yml</code> 中配置部署信息：</li>
</ol>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repository:</span> <span class="string">git@github.com:&lt;用户名&gt;/&lt;用户名&gt;.github.io.git</span></span><br><span class="line">  <span class="attr">branch:</span> <span class="string">master</span></span><br></pre></td></tr></table></figure>

<ol start="4">
<li>一键部署：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo clean &amp;&amp; hexo deploy</span><br></pre></td></tr></table></figure>

<h2 id="进阶优化"><a href="#进阶优化" class="headerlink" title="进阶优化"></a>进阶优化</h2><ul>
<li><strong>图片懒加载</strong>：提升页面加载速度</li>
<li><strong>Pjax 无刷新切换</strong>：提升浏览体验</li>
<li><strong>搜索功能</strong>：安装 <code>hexo-generator-search</code> 插件</li>
<li><strong>评论系统</strong>：推荐 Twikoo 或 Waline</li>
<li><strong>CDN 加速</strong>：通过 Cloudflare 或国内 CDN 服务加速</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Hexo 是一个强大而灵活的博客框架，配合优秀的主题和插件生态，可以打造出极具个性的技术博客。希望本文能帮助你顺利上手，开启属于自己的写作之旅。</p>
<blockquote>
<p>动手实践是最好的学习方式。现在就开始搭建你的博客吧！</p>
</blockquote>
]]></content>
      <categories>
        <category>技术心得</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>博客</tag>
        <tag>前端</tag>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title>Gemini 3.1 Pro深度解析：Google最强推理模型全面评测</title>
    <url>/2026/02/21/Gemini-3-1-Pro%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%EF%BC%9AGoogle%E6%9C%80%E5%BC%BA%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E5%85%A8%E9%9D%A2%E8%AF%84%E6%B5%8B/</url>
    <content><![CDATA[<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>2026年2月19日，Google DeepMind 正式发布了 <strong>Gemini 3.1 Pro</strong>，这是继2025年11月 Gemini 3.0 发布后的又一次重大升级。作为 Google 目前最先进的推理模型，Gemini 3.1 Pro 在多项基准测试中超越了 Claude Opus 4.6 和 GPT-5.2，标志着 Google 在 AI 竞赛中重新夺回了领先地位。</p>
<p>本文将从技术规格、核心特性、基准测试表现、API 定价等多个维度，为你全面解析这款”为复杂任务而生”的 AI 模型。</p>
<h2 id="一、技术规格概览"><a href="#一、技术规格概览" class="headerlink" title="一、技术规格概览"></a>一、技术规格概览</h2><table>
<thead>
<tr>
<th>属性</th>
<th>规格</th>
</tr>
</thead>
<tbody><tr>
<td>发布日期</td>
<td>2026年2月19日</td>
</tr>
<tr>
<td>模型状态</td>
<td>预览版 (Preview)</td>
</tr>
<tr>
<td>上下文窗口</td>
<td><strong>1M tokens</strong> (1,000K)</td>
</tr>
<tr>
<td>最大输出</td>
<td>64K tokens</td>
</tr>
<tr>
<td>模态支持</td>
<td>文本、图像、视频、音频、代码</td>
</tr>
<tr>
<td>架构类型</td>
<td>Dense</td>
</tr>
<tr>
<td>知识截止</td>
<td>2025年1月</td>
</tr>
<tr>
<td>许可证</td>
<td>专有 (Proprietary)</td>
</tr>
</tbody></table>
<p>Gemini 3.1 Pro 延续了 Gemini 3 系列的设计理念，采用<strong>原生多模态</strong>架构，能够同时处理文本、图像、视频、音频等多种输入形式。其最大的亮点在于<strong>100万 token 的超长上下文窗口</strong>，这意味着它可以一次性处理：</p>
<ul>
<li>数十份完整的研究论文</li>
<li>大型代码仓库</li>
<li>数小时的视频内容</li>
<li>复杂的多文档分析任务</li>
</ul>
<h2 id="二、核心特性升级"><a href="#二、核心特性升级" class="headerlink" title="二、核心特性升级"></a>二、核心特性升级</h2><h3 id="2-1-三级思考模式-Thinking-Levels"><a href="#2-1-三级思考模式-Thinking-Levels" class="headerlink" title="2.1 三级思考模式 (Thinking Levels)"></a>2.1 三级思考模式 (Thinking Levels)</h3><p>Gemini 3.1 Pro 引入了<strong>三级思考模式</strong>，允许用户在延迟和推理深度之间灵活权衡：</p>
<table>
<thead>
<tr>
<th>思考级别</th>
<th>特点</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td><strong>LOW</strong></td>
<td>快速响应，轻度推理</td>
<td>简单问答、日常对话</td>
</tr>
<tr>
<td><strong>MEDIUM</strong> (新增)</td>
<td>平衡模式</td>
<td>复杂分析、代码生成</td>
</tr>
<tr>
<td><strong>HIGH</strong></td>
<td>深度推理，最高精度</td>
<td>数学证明、科学推理</td>
</tr>
</tbody></table>
<p>这个新增的 <code>MEDIUM</code> 级别填补了原有 LOW 和 HIGH 之间的空白，为开发者提供了更精细的控制粒度。</p>
<h3 id="2-2-增强的推理能力"><a href="#2-2-增强的推理能力" class="headerlink" title="2.2 增强的推理能力"></a>2.2 增强的推理能力</h3><p>Google 官方表示，Gemini 3.1 Pro 的推理能力相比前代提升了<strong>2倍</strong>。这一提升主要体现在：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 示例：使用 Gemini 3.1 Pro API 进行复杂推理</span></span><br><span class="line"><span class="keyword">import</span> google.generativeai <span class="keyword">as</span> genai</span><br><span class="line"></span><br><span class="line">model = genai.GenerativeModel(<span class="string">&#x27;gemini-3.1-pro-preview&#x27;</span>)</span><br><span class="line">response = model.generate_content(</span><br><span class="line">    <span class="string">&quot;分析以下代码库的架构设计并提出优化建议...&quot;</span>,</span><br><span class="line">    generation_config=&#123;</span><br><span class="line">        <span class="string">&#x27;thinking_level&#x27;</span>: <span class="string">&#x27;HIGH&#x27;</span>  <span class="comment"># 启用深度推理</span></span><br><span class="line">    &#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h3 id="2-3-更高效的-Token-使用"><a href="#2-3-更高效的-Token-使用" class="headerlink" title="2.3 更高效的 Token 使用"></a>2.3 更高效的 Token 使用</h3><p>Gemini 3.1 Pro 在 token 效率方面也有显著改进：</p>
<ul>
<li>更精准的回答，减少冗余输出</li>
<li>优化的思考过程，避免无效 token 消耗</li>
<li>改进的代码生成，输出更简洁</li>
</ul>
<h3 id="2-4-原生多模态能力"><a href="#2-4-原生多模态能力" class="headerlink" title="2.4 原生多模态能力"></a>2.4 原生多模态能力</h3><p>Gemini 3.1 Pro 支持以下多模态输入：</p>
<ul>
<li>📝 <strong>文本</strong>：多语言理解与生成</li>
<li>🖼️ <strong>图像</strong>：图像理解、分析、生成 SVG</li>
<li>🎥 <strong>视频</strong>：视频内容理解与分析</li>
<li>🎵 <strong>音频</strong>：语音识别与处理</li>
<li>💻 <strong>代码</strong>：多语言代码生成与调试</li>
</ul>
<h2 id="三、基准测试表现"><a href="#三、基准测试表现" class="headerlink" title="三、基准测试表现"></a>三、基准测试表现</h2><h3 id="3-1-核心基准测试"><a href="#3-1-核心基准测试" class="headerlink" title="3.1 核心基准测试"></a>3.1 核心基准测试</h3><p>根据 Google 官方发布的 Model Card，Gemini 3.1 Pro 在多项关键基准测试中表现出色：</p>
<table>
<thead>
<tr>
<th>基准测试</th>
<th>得分</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td><strong>ARC-AGI-2</strong></td>
<td>77.1%</td>
<td>推理能力基准，比前代提升2倍</td>
</tr>
<tr>
<td><strong>GPQA Diamond</strong></td>
<td>94.3%</td>
<td>科学问答基准</td>
</tr>
<tr>
<td><strong>AIME 2025</strong></td>
<td>~100%</td>
<td>数学竞赛基准</td>
</tr>
<tr>
<td><strong>MMLU</strong></td>
<td>92%+</td>
<td>综合知识基准</td>
</tr>
</tbody></table>
<h3 id="3-2-与竞品对比"><a href="#3-2-与竞品对比" class="headerlink" title="3.2 与竞品对比"></a>3.2 与竞品对比</h3><p>根据 Artificial Analysis 的评测数据：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Intelligence Index 排名（截至2026年2月）:</span><br><span class="line">1. Gemini 3.1 Pro    - Index: 57 (排名第1/115)</span><br><span class="line">2. Claude Opus 4.6   - 紧随其后</span><br><span class="line">3. GPT-5.2           - 第三</span><br></pre></td></tr></table></figure>

<p>在 Google 官方公布的 16 项基准测试中，Gemini 3.1 Pro 在 <strong>13 项</strong>中取得最佳成绩：</p>
<ul>
<li>✅ 数学推理</li>
<li>✅ 代码生成</li>
<li>✅ 科学问答</li>
<li>✅ 多模态理解</li>
<li>✅ 长上下文处理</li>
</ul>
<blockquote>
<p><strong>注意</strong>：部分评测机构指出，GPT-5.3-Codex 在 16 项基准测试中有 14 项未公布数据，因此部分”胜利”是针对缺席的竞争对手。</p>
</blockquote>
<h3 id="3-3-用户投票-Arena"><a href="#3-3-用户投票-Arena" class="headerlink" title="3.3 用户投票 (Arena)"></a>3.3 用户投票 (Arena)</h3><p>在 LMSYS Chatbot Arena 的用户投票中：</p>
<ul>
<li>Claude Opus 4.6 领先 4 分</li>
<li>Gemini 3.1 Pro 基本持平</li>
<li>两者在实际体验中差距极小</li>
</ul>
<h2 id="四、API-定价与访问"><a href="#四、API-定价与访问" class="headerlink" title="四、API 定价与访问"></a>四、API 定价与访问</h2><h3 id="4-1-定价详情"><a href="#4-1-定价详情" class="headerlink" title="4.1 定价详情"></a>4.1 定价详情</h3><table>
<thead>
<tr>
<th>项目</th>
<th>价格</th>
</tr>
</thead>
<tbody><tr>
<td>输入 tokens</td>
<td><strong>$2.00</strong> &#x2F; 1M tokens</td>
</tr>
<tr>
<td>输出 tokens</td>
<td><strong>$12.00</strong> &#x2F; 1M tokens</td>
</tr>
<tr>
<td>Audio tokens</td>
<td>$2.00 &#x2F; 1M tokens</td>
</tr>
<tr>
<td>缓存写入</td>
<td>$4.50 &#x2F; 1M tokens</td>
</tr>
<tr>
<td>缓存读取</td>
<td>$0.20 &#x2F; 1M tokens</td>
</tr>
</tbody></table>
<p>相比 Claude Opus 4.6，Gemini 3.1 Pro 的定价约为其<strong>50%</strong>，性价比优势明显。</p>
<h3 id="4-2-访问方式"><a href="#4-2-访问方式" class="headerlink" title="4.2 访问方式"></a>4.2 访问方式</h3><p>Gemini 3.1 Pro 可通过以下渠道访问：</p>
<ol>
<li><strong>Gemini API</strong> - 面向开发者</li>
<li><strong>Vertex AI</strong> - 企业级部署</li>
<li><strong>Google AI Studio</strong> - 免费试用</li>
<li><strong>Gemini App</strong> - 消费者端</li>
<li><strong>NotebookLM</strong> - 研究场景</li>
</ol>
<h3 id="4-3-快速上手"><a href="#4-3-快速上手" class="headerlink" title="4.3 快速上手"></a>4.3 快速上手</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用 OpenRouter API</span></span><br><span class="line">curl https://openrouter.ai/api/v1/chat/completions \</span><br><span class="line">  -H <span class="string">&quot;Authorization: Bearer <span class="variable">$OPENROUTER_API_KEY</span>&quot;</span> \</span><br><span class="line">  -H <span class="string">&quot;Content-Type: application/json&quot;</span> \</span><br><span class="line">  -d <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">    &quot;model&quot;: &quot;google/gemini-3.1-pro-preview&quot;,</span></span><br><span class="line"><span class="string">    &quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello!&quot;&#125;]</span></span><br><span class="line"><span class="string">  &#125;&#x27;</span></span><br></pre></td></tr></table></figure>

<h2 id="五、适用场景分析"><a href="#五、适用场景分析" class="headerlink" title="五、适用场景分析"></a>五、适用场景分析</h2><h3 id="5-1-推荐使用场景"><a href="#5-1-推荐使用场景" class="headerlink" title="5.1 推荐使用场景"></a>5.1 推荐使用场景</h3><table>
<thead>
<tr>
<th>场景</th>
<th>推荐指数</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td>复杂代码生成</td>
<td>⭐⭐⭐⭐⭐</td>
<td>React、Python、Golang 表现优异</td>
</tr>
<tr>
<td>多模态分析</td>
<td>⭐⭐⭐⭐⭐</td>
<td>原生多模态支持</td>
</tr>
<tr>
<td>长文档处理</td>
<td>⭐⭐⭐⭐⭐</td>
<td>1M token 上下文</td>
</tr>
<tr>
<td>科学研究</td>
<td>⭐⭐⭐⭐⭐</td>
<td>GPQA 94.3%</td>
</tr>
<tr>
<td>UI&#x2F;UX 设计</td>
<td>⭐⭐⭐⭐⭐</td>
<td>原生 SVG 生成</td>
</tr>
<tr>
<td>日常对话</td>
<td>⭐⭐⭐⭐</td>
<td>可能过于详细</td>
</tr>
</tbody></table>
<h3 id="5-2-不推荐场景"><a href="#5-2-不推荐场景" class="headerlink" title="5.2 不推荐场景"></a>5.2 不推荐场景</h3><ul>
<li>需要极快响应的实时应用（推理较慢）</li>
<li>预算极度敏感的项目</li>
<li>需要开源&#x2F;可本地部署的场景</li>
</ul>
<h2 id="六、与竞品对比总结"><a href="#六、与竞品对比总结" class="headerlink" title="六、与竞品对比总结"></a>六、与竞品对比总结</h2><table>
<thead>
<tr>
<th>维度</th>
<th>Gemini 3.1 Pro</th>
<th>Claude Opus 4.6</th>
<th>GPT-5.2</th>
</tr>
</thead>
<tbody><tr>
<td>推理能力</td>
<td>⭐⭐⭐⭐⭐</td>
<td>⭐⭐⭐⭐⭐</td>
<td>⭐⭐⭐⭐</td>
</tr>
<tr>
<td>上下文长度</td>
<td>1M tokens</td>
<td>200K tokens</td>
<td>400K tokens</td>
</tr>
<tr>
<td>多模态</td>
<td>⭐⭐⭐⭐⭐</td>
<td>⭐⭐⭐⭐</td>
<td>⭐⭐⭐⭐</td>
</tr>
<tr>
<td>代码生成</td>
<td>⭐⭐⭐⭐⭐</td>
<td>⭐⭐⭐⭐⭐</td>
<td>⭐⭐⭐⭐⭐</td>
</tr>
<tr>
<td>价格</td>
<td>💰💰</td>
<td>💰💰💰💰</td>
<td>💰💰💰</td>
</tr>
<tr>
<td>推理速度</td>
<td>🐢🐢</td>
<td>🐢🐢</td>
<td>🐇🐇</td>
</tr>
</tbody></table>
<h2 id="七、总结"><a href="#七、总结" class="headerlink" title="七、总结"></a>七、总结</h2><p>Gemini 3.1 Pro 代表了 Google DeepMind 在大模型领域的最新成就。其核心优势在于：</p>
<ol>
<li><strong>卓越的推理能力</strong> - ARC-AGI-2 得分 77.1%，相比前代翻倍</li>
<li><strong>超长上下文</strong> - 1M token 窗口，处理大规模文档毫无压力</li>
<li><strong>原生多模态</strong> - 一站式解决多种输入需求</li>
<li><strong>高性价比</strong> - 价格仅为竞品的一半</li>
<li><strong>灵活的思考级别</strong> - LOW&#x2F;MEDIUM&#x2F;HIGH 三档可选</li>
</ol>
<p>当然，它也存在一些不足：</p>
<ul>
<li>推理速度相对较慢</li>
<li>目前仅提供预览版，稳定性有待验证</li>
<li>闭源模型，无法本地部署</li>
</ul>
<p><strong>推荐选择</strong>：如果你的应用需要处理复杂推理任务、长文档分析或多模态输入，Gemini 3.1 Pro 是目前的最佳选择之一。如果更看重响应速度，可以考虑 GPT-5.2 或 Claude Sonnet 系列。</p>
<hr>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a href="https://deepmind.google/models/model-cards/gemini-3-1-pro/">Gemini 3.1 Pro Model Card - Google DeepMind</a></li>
<li><a href="https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/">Gemini 3.1 Pro 官方公告 - Google Blog</a></li>
<li><a href="https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/3-1-pro">Gemini 3.1 Pro API 文档 - Vertex AI</a></li>
<li><a href="https://artificialanalysis.ai/models/gemini-3-1-pro-preview">AI Model Analysis - Artificial Analysis</a></li>
</ul>
]]></content>
      <categories>
        <category>AI前沿</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>大模型</tag>
        <tag>Gemini</tag>
        <tag>Google</tag>
        <tag>DeepMind</tag>
      </tags>
  </entry>
</search>
